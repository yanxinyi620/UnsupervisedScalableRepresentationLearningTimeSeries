3. Unsupervised Training

我们寻求训练一个仅有编码器的架构，避免像Malhotra等人（2017）所做的基于自动编码器的标准表示学习方法那样，需要与解码器联合训练，因为这些会引起较大的计算成本。为此，我们引入了一种新颖的时间序列的三倍频损失，其灵感来自于被称为word2vec(Mikolov等人，2013)的成功且现在已经很经典的词表示学习方法。所提出的三重损失使用原始的基于时间的采样策略来克服在未标记数据上学习的挑战。据我们所知，这项工作是时间序列文献中第一个在完全无监督环境下依赖三倍子损失的工作。

其目标是确保相似的时间序列获得相似的表示，而不需要监督来学习这种相似性。三重损失有助于实现前者（Schroff等，2015），但需要提供成对的相似输入，因此对后者提出了挑战。以往使用三重损失的时间序列的监督作品都假设数据是有标注的，而我们引入了一种无监督的基于时间的标准来选择相似的时间序列对，并考虑到不同长度的时间序列，遵循word2vec的直觉。word2vec的CBOW模型所做的假设有两个方面。一方面，一个词的上下文的表示可能应该与这个词的上下文接近（Goldberg & Levy，2014），另一方面，与随机选择的词的上下文保持距离，因为它们可能与原词的上下文无关。相应的损失就会促使（上下文，单词）和（上下文，随机单词）的对子是可以线性分离的。这就是所谓的负采样。


